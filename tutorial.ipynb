{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bafcc657",
   "metadata": {},
   "source": [
    " [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LotsoTeddy/ark-samples/tutorial.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "<hr/>\n",
    "<img src=\"https://portal.volccdn.com/obj/volcfe/logo/appbar_logo_dark.2.svg?sanitize=true\" align=center>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc44f8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is a **novice-friendly tutorial** for Volengine ARK SDK and API. This tutorial is able to help you to build your own intelligent applications through agent, knowledge base, and other amazing features.\n",
    "\n",
    "[Volengine ARK](https://www.volcengine.com/product/ark) provides a development platform with large model services, offering feature-rich, secure and price-competitive model calling services, as well as end-to-end functions such as model data, fine-tuning, reasoning, evaluation, and so on, to comprehensively guarantee your AI application development landing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690eb12",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc1bba",
   "metadata": {},
   "source": [
    "### Why ARK?\n",
    "\n",
    "ARK is a platform that supports multiple kinds of models running. Ark has the following advantages:\n",
    "\n",
    "- **Security and Mutual Trust**: Large model security and trust program strictly protects the model and information security of model providers and model users, click to view the white paper on security and mutual trust.\n",
    "- **Selected Models**: Supporting multi-industry models for various business scenarios, providing rich platform applications and tools to help you build your own innovative scenarios.\n",
    "- **Strong Arithmetic Power**: Based on the volcano's Wanka resource pool, we provide sufficient high-performance GPU resources to provide you with end-to-end modeling services including model fine-tuning, evaluation, and inference.\n",
    "- **Enterprise-level services**: provide professional service system support, professional product operation and sales delivery services to meet the needs of enterprise application construction and delivery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab1bdb",
   "metadata": {},
   "source": [
    "### Productions\n",
    "\n",
    "- Large models (e.g., Doubao-*, Deepseek-*, etc.)\n",
    "- Knowledge base\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0615505",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225f331",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    " Install Volcengine ARK SDK and ARK Agent SDK via `pip`. \n",
    " \n",
    " The source code of ARK SDK is available [here](https://github.com/volcengine/volcengine-python-sdk).\n",
    " The source code of ARK Agent SDK is available [here](https://github.com/volcengine/ai-app-lab/tree/main/arkitect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7240f703",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install 'volcengine-python-sdk[ark]' -q\n",
    "%pip install arkitect -q\n",
    "%pip install chromadb -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83256f06",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "Before running this tutorial, you should generate your ARK API KEY (see [here](https://www.volcengine.com/docs/82379/1541594))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86675b9",
   "metadata": {},
   "source": [
    "#### Notebook\n",
    "\n",
    "In this tutorial, set `YOUR_ARK_API_KEY` as an environment and a global variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = \"YOUR_ARK_API_KEY\"\n",
    "ARK_API_KEY = os.environ[\"ARK_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd1abb",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "\n",
    "If you run this tutorial in Google Colab, you can set your ARK api key followed by [here](). Then run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"ARK_API_KEY\"] = userdata.get(\"ARK_API_KEY\")\n",
    "ARK_API_KEY = os.environ[\"ARK_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d662a02",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3088a6",
   "metadata": {},
   "source": [
    "In this tutorial, we define some default large models for different tasks. You can change your referenced models here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc31129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text processing\n",
    "DEFAULT_LLM = \"doubao-1.5-pro-32k-250115\"\n",
    "\n",
    "# for image understanding\n",
    "DEFAULT_VLM = \"doubao-1.5-vision-pro-32k-250115\"\n",
    "\n",
    "# for video generation\n",
    "VIDEO_GENERATION_LM = \"doubao-seedance-1-0-lite-i2v-250428\"\n",
    "\n",
    "# for text embedding, when building RAG\n",
    "EMBEDDING_MODEL = \"doubao-embedding-text-240715\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b3453",
   "metadata": {},
   "source": [
    "Simplest, you can chat with a model by the chat completion interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd015ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from volcenginesdkarkruntime import Ark\n",
    "\n",
    "client = Ark(api_key=ARK_API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_LLM,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Slogan of Bytedance?\"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b8beb",
   "metadata": {},
   "source": [
    "Furthermore, you can send a *system prompt* by specifying the role as *system*, which can help you to control the behavior of the model. For example, you can use the system prompt to tell the model to do some translations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453accfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_LLM,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Translate the input text from English to Chinese, French, and Japanese.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Inspire Creativity, Enrich Life!\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dbee44",
   "metadata": {},
   "source": [
    "# Basic Usage\n",
    "\n",
    "This section introduces the basic usage and features of ARK SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b5f935",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "ARK's model family includes a wide range of models. Here we list some primary models and its abilities:\n",
    "\n",
    "| Model ID                                      | Image Understanding | Video Generation | Function Calling |\n",
    "|-----------------------------------------------|---------------------|------------------|------------------|\n",
    "| doubao-1-5-pro-256k-250115                    |                     |                | ✅               |\n",
    "| doubao-1-5-thinking-pro-250415                |                     |                | ✅                 |\n",
    "| doubao-1-5-thinking-pro-m-250415              | ✅                  |                | ✅               |\n",
    "| doubao-1.5-vision-pro-250328                  | ✅                  |                  |                  |\n",
    "| doubao-seedance-1-0-lite-i2v-250428           |                     | ✅               |                  |\n",
    "| deepseek-r1-250120                            |                   |                  |✅                  |\n",
    "| deepseek-v3-250324                            |                   |                  |✅                  |\n",
    "| doubao-1-5-pro-32k-250115                     |                   |                  |✅                  |\n",
    "| doubao-1-5-lite-32k-250115                    |                   |                  |✅                  |\n",
    "\n",
    "The full API reference can be found [here](https://www.volcengine.com/docs/82379/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d8bb9",
   "metadata": {},
   "source": [
    "## Text Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fcf558",
   "metadata": {},
   "source": [
    "### Single-turn Chat\n",
    "\n",
    "Single-turn chat is the simplest form of interaction with a large language model. Single-turn chat generally without any context information. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed9301",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_LLM, messages=[{\"role\": \"user\", \"content\": \"Who are you?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca05f4",
   "metadata": {},
   "source": [
    "### Multi-turn Chat\n",
    "\n",
    "Generally, multi-turn chat generally comes with context, e.g., user's historical messages and model's response. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first turn chat\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_LLM,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Your name is Bytedancer.\"}],\n",
    ")\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "print(\"The first turn response:\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# The second turn chat\n",
    "# In this turn, we carry the model response (`content`) from the last turn\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_LLM,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Your name is Bytedancer.\"},\n",
    "        {\"role\": \"assistant\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"Do you remember your name?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"\\nThe second turn response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db40b92",
   "metadata": {},
   "source": [
    "### Stream Chat\n",
    "\n",
    "Stream chat (i.e., make model response to be streaming) can reduce the user's waiting time when the model's output is too long. You can enable stream chat by setting the `stream` as `True`, then the output will be printed gradually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e817e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=DEFAULT_LLM,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a model assistant\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please help me to write an introduction of Bytedance with nearly 300 words.\",\n",
    "        },\n",
    "    ],\n",
    "    stream=True,  # streaming output\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if not chunk.choices:\n",
    "        continue\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5362c",
   "metadata": {},
   "source": [
    "## Vision Capabilities\n",
    "\n",
    "ARK provides capabilities about multi-media, such as vision and sounds. Here we introduce the vision-related demos. The vision-related task is divided into image understanding and video generation:\n",
    "- Image understanding: this task can read information from one or several images and return the content to the user\n",
    "- Video generation: this task can generate video from text and images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf21d433",
   "metadata": {},
   "source": [
    "### Image understanding\n",
    "\n",
    "We use the default vision model to understand the following image:\n",
    "\n",
    "![demo_image](https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/cat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff58d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"https://ark-tutorial.tos-cn-beijing.volces.com/assets/images/cat.png\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=DEFAULT_VLM,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": \"Please describe this image with details.\", \"type\": \"text\"},\n",
    "                {\"image_url\": {\"url\": IMAGE_PATH}, \"type\": \"image_url\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f184b5f",
   "metadata": {},
   "source": [
    "### Video generation\n",
    "\n",
    "The following demo shows generating a video according to a static image and prompt.\n",
    "\n",
    "The video generation is asynchronous, hence the generation goes through two stages:\n",
    "1. Send generation request\n",
    "   - Input: prompt, image (optional), and other parameters\n",
    "   - Output: generation task ID\n",
    "2. Check the status of the generation\n",
    "\n",
    "The entire process is shown in the following code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48604e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"1. Send generation request\")\n",
    "response = client.content_generation.tasks.create(\n",
    "    model=\"doubao-seaweed-241128\",\n",
    "    content=[\n",
    "        {\n",
    "            \"text\": \"Please generate a video with a cat running. --ratio 16:9\",\n",
    "            \"type\": \"text\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "tid = response.id\n",
    "print(f\"Video generation task {tid} submitted.\")\n",
    "\n",
    "print(\"\\n2. Check the status of the generation\")\n",
    "MAX_RETRIES = 100\n",
    "for _ in range(MAX_RETRIES):\n",
    "    response = client.content_generation.tasks.get(task_id=tid)\n",
    "    status = response.status\n",
    "\n",
    "    if status == \"succeeded\":\n",
    "        print(\n",
    "            f\"Successfully! Your video can be download from {response.content.video_url}\"\n",
    "        )\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Current status: {status}\")\n",
    "\n",
    "    time.sleep(10)  # check every 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff7215",
   "metadata": {},
   "source": [
    " For more models that support video generation, you can visit [here](https://www.volcengine.com/docs/82379/1366799#%E6%94%AF%E6%8C%81%E6%A8%A1%E5%9E%8B).\n",
    " \n",
    " If you want to make the video more vivid, maybe you need [prompt refine](https://www.promptrefine.com/prompt/new)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a675bd4",
   "metadata": {},
   "source": [
    "# [WIP] Agent\n",
    "\n",
    "Here we introduce the architecture and key concepts of Arkitect.\n",
    "\n",
    "- `Context`: Maintain the conversation state and coordinate the LLM call and tool execution logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3d9fc",
   "metadata": {},
   "source": [
    "## Minimal Agent\n",
    "\n",
    "You can build a minimal agent through the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkitect.core.component.context.context import Context\n",
    "\n",
    "# initialize context\n",
    "ctx = Context(model=DEFAULT_LLM)\n",
    "await ctx.init()\n",
    "\n",
    "agent_name = \"Meeting assistant\"\n",
    "message = \"who are you?\"\n",
    "completion = await ctx.completions.create(\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": f\"your name is {agent_name}\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42fbce6",
   "metadata": {},
   "source": [
    "## Tool\n",
    "\n",
    "Agent uses a tool by function calling to finish a task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17358fd1",
   "metadata": {},
   "source": [
    "### Function Tool\n",
    "\n",
    "We use python tool to implement some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87329e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkitect.core.component.context.context import Context\n",
    "from arkitect.core.component.context.model import ToolChunk\n",
    "\n",
    "\n",
    "def get_weather(city: str, next_n_days: int) -> str:\n",
    "    \"\"\"get the weather of a city\n",
    "\n",
    "    Args:\n",
    "        city (str): city name\n",
    "        next_n_days (int): next n days. Need to be a positive integer.\n",
    "\n",
    "    Returns:\n",
    "        str: description of next_n_days' weather\n",
    "    \"\"\"\n",
    "    print(\"[Tool] Invoke get_weather tool.\")\n",
    "    return \"Weather at {} is sunny\".format(city)\n",
    "\n",
    "\n",
    "async def context_chat_with_tools(message: str):\n",
    "    ctx = Context(\n",
    "        model=\"doubao-1.5-pro-32k-250115\",\n",
    "        tools=[get_weather],  # function call here.\n",
    "    )\n",
    "    await ctx.init()\n",
    "\n",
    "    completion = await ctx.completions.create([{\"role\": \"user\", \"content\": message}])\n",
    "\n",
    "    async for chunk in completion:\n",
    "        if not isinstance(chunk, ToolChunk):\n",
    "            print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "\n",
    "await context_chat_with_tools(\"What's the weather like in Beijing tomorrow?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58553c22",
   "metadata": {},
   "source": [
    "### Build-in Tool\n",
    "\n",
    "We provide some built-in tools to finish some common tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a7ec0e",
   "metadata": {},
   "source": [
    "#### Link Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991c9e6",
   "metadata": {},
   "source": [
    "[TODO]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec13ea",
   "metadata": {},
   "source": [
    "#### Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18147132",
   "metadata": {},
   "source": [
    "[TODO]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef562b8",
   "metadata": {},
   "source": [
    "### MCP Tool\n",
    "\n",
    "We can connect a MCP server to use its tool. Here we list some tools provided by XXX MCP server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60103708",
   "metadata": {},
   "source": [
    "**MCP Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkitect.core.component.context.context import Context\n",
    "from arkitect.core.component.tool.mcp_client import MCPClient\n",
    "from arkitect.core.component.context.model import ToolChunk\n",
    "\n",
    "\n",
    "async def context_chat_with_tools_with_mcp_clients():\n",
    "    mcp_client = MCPClient(\n",
    "        name=\"TimeTools\",\n",
    "        command=\"python\",\n",
    "        arguments=[\"-m\", \"mcp_server_time\", \"--local-timezone\", \"Asia/Shanghai\"],\n",
    "    )\n",
    "\n",
    "    first_round_message = \"What time is it in Beijing time now?\"\n",
    "    ctx = Context(\n",
    "        model=\"doubao-1.5-pro-32k-250115\",\n",
    "        tools=[mcp_client],\n",
    "    )\n",
    "    await ctx.init()\n",
    "\n",
    "    completion = await ctx.completions.create(\n",
    "        [{\"role\": \"user\", \"content\": first_round_message}], stream=True\n",
    "    )\n",
    "    async for chunk in completion:\n",
    "        if isinstance(chunk, ToolChunk):\n",
    "            continue\n",
    "        else:\n",
    "            print(chunk.choices[0].delta.content, end=\"\")\n",
    "    await mcp_client.cleanup()  # Pay attention to cleanup!!!\n",
    "\n",
    "\n",
    "await context_chat_with_tools_with_mcp_clients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79436f2a",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1635e4",
   "metadata": {},
   "source": [
    "### Build a Knowledge Base\n",
    "\n",
    "We use `chromadb` to implement vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a972d2c",
   "metadata": {},
   "source": [
    "Building a simple knowledge base needs the following steps:\n",
    "\n",
    "1. Initialize chromadb vector database\n",
    "2. Prepare your data\n",
    "3. Embedding your data from raw/human-friendly format to vector format\n",
    "4. Indexing the data vector\n",
    "5. Creating a function for data searching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863c678",
   "metadata": {},
   "source": [
    "**Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f70269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# create a `chromadb` client\n",
    "chroma_client = chromadb.Client()\n",
    "# create a collection (i.e., table in traditional database) in client\n",
    "collection = chroma_client.create_collection(\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821dece",
   "metadata": {},
   "source": [
    "**Data Preparation**\n",
    "\n",
    "Here we prepare a list of event happened in some years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ba75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [\n",
    "    \"In 1936, Alan Turing proposed the Turing machine model, laying the theoretical foundation for modern computers;\",\n",
    "    \"In 1949, Maurice Wilkes completed EDSAC, the first electronic computer to implement the stored-program concept.\",\n",
    "    \"In 1957, John Backus and his team developed FORTRAN, the first widely used high-level programming language.\",\n",
    "    \"In 1965, Gordon Moore proposed Moore's Law, predicting that the number of transistors in integrated circuits would double approximately every two years.\",\n",
    "    \"In 1969, Ken Thompson and Dennis Ritchie developed the Unix operating system at Bell Labs, which was written in the C programming language.\",\n",
    "    \"In 1984, Richard Stallman released the GNU General Public License (GPL), driving the free software movement.\",\n",
    "    \"In 1991, Linus Torvalds created the Linux kernel, which was released under the GPL license.\",\n",
    "    \"In 2000, Fabrice Bellard developed FFmpeg, an open-source multimedia framework supporting audio/video codecs and streaming processing.\",\n",
    "    \"In 2012, Geoffrey Hinton's team used the deep convolutional network AlexNet in the ImageNet competition, sparking the resurgence of deep learning.\",\n",
    "    \"In 2017, Ashish Vaswani and colleagues published the paper *Attention Is All You Need*, introducing the Transformer architecture that revolutionized natural language processing.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444deb5a",
   "metadata": {},
   "source": [
    "**Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67a601",
   "metadata": {},
   "source": [
    "Then we embed the text to vertors using the *embedding model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reponse = client.embeddings.create(model=EMBEDDING_MODEL, input=data_list)\n",
    "embedding_list = [response.data[i].embedding for i in range(len(response.data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c23b16",
   "metadata": {},
   "source": [
    "**Indexing**\n",
    "\n",
    "The embedding text should be added into the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487598e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "collection.add(\n",
    "    ids=[str(uuid.uuid4()) for i in range(len(data_list))],\n",
    "    documents=data_list,\n",
    "    embeddings=embedding_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba47730",
   "metadata": {},
   "source": [
    "**Search function**\n",
    "\n",
    "Build a search interface to search for a specific string in a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_vb(query: str) -> list[str]:\n",
    "    \"\"\"Retrieve documents similar to the query text in the vector database.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query text to be retrieved (e.g., \"Who proposed the Turing machine model?\")\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of the top 2 most similar document contents retrieved (sorted by vector similarity)\n",
    "    \"\"\"\n",
    "    # We retrieve the top 2 most similar documents from the vector database\n",
    "    TOP_N = 2\n",
    "\n",
    "    # We need to embed the input string to realize vector similarity search\n",
    "    response = client.embeddings.create(model=EMBEDDING_MODEL, input=[query])\n",
    "\n",
    "    result = collection.query(\n",
    "        query_embeddings=response.data[0].embedding, n_results=TOP_N\n",
    "    )\n",
    "    return result[\"documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136c366",
   "metadata": {},
   "source": [
    "## Equip to AgentAW\n",
    "\n",
    "The knowledge base should be equipped to enable RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5dc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arkitect.core.component.context.context import Context\n",
    "from arkitect.core.component.context.model import ToolChunk\n",
    "\n",
    "\n",
    "async def context_chat_with_vb(message: str):\n",
    "    ctx = Context(\n",
    "        model=\"doubao-1.5-pro-32k-250115\",\n",
    "        tools=[search_vb],  # function call here.\n",
    "    )\n",
    "    await ctx.init()\n",
    "\n",
    "    completion = await ctx.completions.create([{\"role\": \"user\", \"content\": message}])\n",
    "\n",
    "    async for chunk in completion:\n",
    "        if not isinstance(chunk, ToolChunk):\n",
    "            print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "\n",
    "await context_chat_with_vb(\"What did Hinton and his team do in 2012?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576fb8b7",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee995b",
   "metadata": {},
   "source": [
    "### Sequencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacbb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa0ff5",
   "metadata": {},
   "source": [
    "### Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c71fc",
   "metadata": {},
   "source": [
    "### ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e274e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffaa6f7",
   "metadata": {},
   "source": [
    "### Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8dc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9230d0f",
   "metadata": {},
   "source": [
    "## Context Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e0921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6704fd8c",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657c1ee",
   "metadata": {},
   "source": [
    "### Function calling Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c28dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c435ef",
   "metadata": {},
   "source": [
    "### LLM callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446dcb09",
   "metadata": {},
   "source": [
    "### ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc7d06",
   "metadata": {},
   "source": [
    "## Human-in-the-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ffdc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e0186",
   "metadata": {},
   "source": [
    "# [WIP] Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31352310",
   "metadata": {},
   "source": [
    "## Custom service\n",
    "\n",
    "This demo shows how to create a custom service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacf53e",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "**Task**: Receive a message from a user and send a response according to preset question/answer pairs.\n",
    "\n",
    "**Input**: A message from a user.\n",
    "\n",
    "**Output**: A response to the user's message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c7a36",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "1. Receive user's message\n",
    "2. Retrieve relevant documents from knowledge base (i.e.,vector database)\n",
    "3. Generate a response using Doubao LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60133c0",
   "metadata": {},
   "source": [
    "### Components\n",
    "\n",
    "**Knowledge base**: A collection of question/answer pairs.\n",
    "\n",
    "**Tools**: `xxx`, `xxx`, and `xxx` tools for xxx."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7eabb5",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3771da",
   "metadata": {},
   "source": [
    "**Build knowledge base**\n",
    "\n",
    "We build a knowledge base from the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108cfdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6dcd1",
   "metadata": {},
   "source": [
    "## Information summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64061cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b0374d",
   "metadata": {},
   "source": [
    "## Recommendation engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f35800c",
   "metadata": {},
   "source": [
    "## Platform monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3468dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7de02",
   "metadata": {},
   "source": [
    "# [WIP] Compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f37abe",
   "metadata": {},
   "source": [
    "## OpenAI API\n",
    "\n",
    "Reference [here](https://www.volcengine.com/docs/82379/1330626)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
